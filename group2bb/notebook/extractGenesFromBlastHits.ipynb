{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a109cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "#from BCBio import GFF\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc0246c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## none of these are currently being used\n",
    "#baf_gff = 'genomes/bafPKo.gff'\n",
    "#bb31_gff = 'genomes/bbB31.gff'\n",
    "#bga_gff = 'genomes/bgaPBi.gff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b81c8e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mf019/bioinformatics/longread_GWAS/group2bb/notebook\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d3696f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pangenome_reference = '/Users/mf019/bioinformatics/longread_GWAS/lipoPredict/output/lr_roary/LR_pan_genome_reference.fa'\n",
    "sr_pangenome_reference = '/Users/mf019/bioinformatics/longread_GWAS/lipoPredict/output/sr_roary/SR_pan_genome_reference.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f310d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../output/lr_group_to_ID_mapping.txt'):\n",
    "# Lets make our group to ID mapping.\n",
    "    with open(lr_pangenome_reference) as f:\n",
    "        with open('../output/lr_group_to_ID_mapping.txt', 'w') as out:\n",
    "            lines = f.readlines()\n",
    "            groups = []\n",
    "            for line in lines:\n",
    "                if line.startswith('>'):\n",
    "                    line = line.replace('>', '').split(' ')\n",
    "                    seqID = line[0]\n",
    "                    groupID = ' '.join(line[1::])\n",
    "                    if 'BB' in groupID:\n",
    "                        print(1,groupID)\n",
    "                        groupID = groupID.split('BB')[0::] # whateven\n",
    "                        print(2,groupID)\n",
    "                        BBgroupID = 'BB'.join(groupID) # why\n",
    "                        print(3,BBgroupID)\n",
    "                        out.write(f'{seqID}\\t{BBgroupID}') # ok whatever\n",
    "                    else:\n",
    "                        out.write(f'{seqID}\\t{groupID}')\n",
    "\n",
    "if not os.path.exists('../output/sr_group_to_ID_mapping.txt'):\n",
    "    with open(sr_pangenome_reference) as f:\n",
    "        with open('../output/sr_group_to_ID_mapping.txt', 'w') as out:\n",
    "            lines = f.readlines()\n",
    "            groups = []\n",
    "            for line in lines:\n",
    "                if line.startswith('>'):\n",
    "                    line = line.replace('>', '').split(' ')\n",
    "                    seqID = line[0]\n",
    "                    groupID = ' '.join(line[1::])\n",
    "                    if 'BB' in groupID:\n",
    "                        print(1,groupID)\n",
    "                        groupID = groupID.split('BB')[0::] # whateven\n",
    "                        print(2,groupID)\n",
    "                        BBgroupID = 'BB'.join(groupID) # why\n",
    "                        print(3,BBgroupID)\n",
    "                        out.write(f'{seqID}\\t{BBgroupID}') # ok whatever\n",
    "                    else:\n",
    "                        out.write(f'{seqID}\\t{groupID}')\n",
    "        #print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dfbb51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set blast results\n",
    "lr_blast_results = '../output/lr_pan_genome_blast.topHit.tsv'\n",
    "sr_blast_results = '../output/sr_pan_genome_blast.topHit.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75fc253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fields=\"query acc.ver, subject acc.ver, % identity, alignment length, mismatches, gap opens, q. start, q. end, s. start, s. end, evalue, bit score\"\n",
    "results = pandas.read_csv(lr_blast_results, sep = '\\t', header=None) # read in blast results .tsv\n",
    "\n",
    "#create ID to Group translation table\n",
    "#ID2GROUP.tsv is created by sed on the pan-genome reference fasta # created above......\n",
    "id2group = pandas.read_csv('../output/lr_group_to_ID_mapping.txt', sep = '\\t', header=None)\n",
    "id2group = pandas.DataFrame({\"ID\":id2group[0],\"group\":id2group[1]})\n",
    "\n",
    "#create a dataframe containing group, geneID, %identity, alignment length, and E-score\n",
    "hits = pandas.DataFrame({\"ID\":results[0],\n",
    "                         \"gene\":results[1],\n",
    "                         \"percent_ident\":results[2],\n",
    "                         \"alignment_length\": results[3],\n",
    "                         \"E-score\": results[10]})\n",
    "hits = hits.drop_duplicates() # I have no idea why blast output duplicates for each hit.... drop them\n",
    "ids = list(hits['ID'].unique()) # pull out unique ID numbers to filter the list by.\n",
    "hits = hits.loc[(hits[\"ID\"].isin(ids)) & (hits[\"gene\"].str.startswith(\"gene-BB\"))] # filter list by IDs then pull out genes starting with gene-BB.\n",
    "hits = hits.merge(id2group,how='left') #merge em together\n",
    "####\n",
    "#\n",
    "# To make the gene names easier to work with, use str method to remove prefix 'gene-'. I originally had it set to automatically strip that but due to the\n",
    "# GFF/annotations having that same prefix, opted to leave it included for easier parsing/comparison. It should probably be removed.\n",
    "#\n",
    "####\n",
    "translatedhits = hits.iloc[:,[0,5,1,2,3,4]] #reorder dataframe\n",
    "#print(translatedhits) #make sure it isn't broken.\n",
    "\n",
    "#translatedhits.to_csv(\"../output/lr_groupID_to_BBgene.tsv\", sep='\\t',header=True,index=None) #write to tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b454564",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Index(['group'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/59/fs0fxd1x1wx1j_stw1ccjbcr0000gp/T/ipykernel_35484/2140611798.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                          \"E-score\": results[10]})\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Sort the hits DataFrame by percent_ident in descending order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msorted_hits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'percent_ident'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Drop duplicates based on the 'group' column, keeping only the first occurrence (topmost hit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtop_hits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_hits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'group'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pull out unique ID numbers to filter the list by.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gene\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gene-BB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# filter list by IDs then pull out genes starting with gene-BB.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6563\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6564\u001b[0m         \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ignore_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6566\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6568\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6694\u001b[0m         \u001b[0;31m# Otherwise, raise a KeyError, same as if you try to __getitem__ with a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6695\u001b[0m         \u001b[0;31m# key that doesn't exist.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6696\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6698\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6701\u001b[0m             \u001b[0;31m# GH#45236 This is faster than get_group_index below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Index(['group'], dtype='object')"
     ]
    }
   ],
   "source": [
    "#Fields=\"query acc.ver, subject acc.ver, % identity, alignment length, mismatches, gap opens, q. start, q. end, s. start, s. end, evalue, bit score\"\n",
    "results = pandas.read_csv(sr_blast_results, sep = '\\t', header=None) # read in blast results .tsv\n",
    "\n",
    "#create ID to Group translation table\n",
    "#ID2GROUP.tsv is created by sed on the pan-genome reference fasta # created above......\n",
    "id2group = pandas.read_csv('../output/sr_group_to_ID_mapping.txt', sep = '\\t', header=None)\n",
    "id2group = pandas.DataFrame({\"ID\":id2group[0],\"group\":id2group[1]})\n",
    "\n",
    "#create a dataframe containing group, geneID, %identity, alignment length, and E-score\n",
    "hits = pandas.DataFrame({\"ID\":results[0],\n",
    "                         \"gene\":results[1],\n",
    "                         \"percent_ident\":results[2],\n",
    "                         \"alignment_length\": results[3],\n",
    "                         \"E-score\": results[10]})\n",
    "# Sort the hits DataFrame by percent_ident in descending order\n",
    "sorted_hits = hits.sort_values('percent_ident', ascending=False)\n",
    "# Drop duplicates based on the 'group' column, keeping only the first occurrence (topmost hit)\n",
    "top_hits = sorted_hits.drop_duplicates(subset='group', keep='first')\n",
    "ids = list(hits['ID'].unique()) # pull out unique ID numbers to filter the list by.\n",
    "\n",
    "hits = hits.loc[(hits[\"ID\"].isin(ids)) & (hits[\"gene\"].str.startswith(\"gene-BB\"))] # filter list by IDs then pull out genes starting with gene-BB.\n",
    "hits = hits.merge(id2group,how='left') #merge em together\n",
    "####\n",
    "#\n",
    "# To make the gene names easier to work with, use str method to remove prefix 'gene-'. I originally had it set to automatically strip that but due to the\n",
    "# GFF/annotations having that same prefix, opted to leave it included for easier parsing/comparison. It should probably be removed.\n",
    "#\n",
    "####\n",
    "translatedhits = hits.iloc[:,[0,5,1,2,3,4]] #reorder dataframe\n",
    "#print(translatedhits) #make sure it isn't broken.\n",
    "\n",
    "#translatedhits.to_csv(\"../output/sr_groupID_to_BBgene.tsv\", sep='\\t',header=True,index=None) #write to tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed2b59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## parse GTF file\n",
    "#record = {}\n",
    "#in_handle = open(bb31_gff)\n",
    "#for rec in GFF.parse(in_handle):\n",
    "#    record = rec.features\n",
    "#for i in enumerate(record):\n",
    "#    pprint.pprint(record[i[0]].qualifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1f57fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_groups = translatedhits[translatedhits.duplicated(subset='group', keep=False)]['group'].unique()\n",
    "unique_groups = translatedhits['group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c69e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
