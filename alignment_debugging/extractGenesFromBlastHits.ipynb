{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a109cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                LIBRARIES AND MODULES                #\n",
    "#######################################################\n",
    "import pandas\n",
    "import pprint\n",
    "import gffutils\n",
    "import re\n",
    "from   Bio                    import SeqIO\n",
    "from   Bio.Seq                import Seq, MutableSeq, reverse_complement, transcribe, back_transcribe, translate\n",
    "from   Bio.SeqFeature         import SeqFeature, SimpleLocation\n",
    "from   Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from   BCBio                  import GFF\n",
    "from   BCBio.GFF              import GFFExaminer\n",
    "\n",
    "#######################################################\n",
    "#                     INPUT FILES                     #\n",
    "#######################################################\n",
    "\n",
    "bb31_gff = '../raw/blast/bbB31.gff'\n",
    "bb31_fna = '../raw/blast/bbB31.fna'\n",
    "\n",
    "#pangen_ref = '../raw/pan_genome_reference.fa' # I will eventually add in the whole blast report generation step and ID_to_group.tsv generation step. maybe that's worthy of its own script?\n",
    "blast_results = '../raw/blast/pan_genome_blast.topHit.tsv'\n",
    "seqID_to_group = '../raw/blast/ID2GROUP.tsv'\n",
    "\n",
    "#######################################################\n",
    "#                     OUTPUT FILES                    #\n",
    "#######################################################\n",
    "\n",
    "#ID_to_group  = \"../raw/ID_to_group.tsv\"\n",
    "gwas_output_table = \"../raw/groupID_to_BBgene.tsv\"\n",
    "wetlab_output_table = \"../raw/groupID_to_BBgene_wetlab.tsv\"\n",
    "all_genes_table = \"../raw/all_genes_peptide_info.tsv\"\n",
    "\n",
    "#######################################################\n",
    "#               PLASMID TRANSLATION TABLE             #\n",
    "#######################################################\n",
    "\n",
    "plasmid_name_table={\"NC_001318.1\":\"chromosome\",\n",
    "                    \"NC_000957.1\":\"lp5\",\n",
    "                    \"NC_001904.1\":\"cp9\",\n",
    "                    \"NC_001849.2\":\"lp17\",\n",
    "                    \"NC_000955.2\":\"lp21\",\n",
    "                    \"NC_001850.1\":\"lp25\",\n",
    "                    \"NC_001903.1\":\"cp26\",\n",
    "                    \"NC_001851.2\":\"lp28-1\",\n",
    "                    \"NC_001852.1\":\"lp28-2\",\n",
    "                    \"NC_001853.1\":\"lp28-3\",\n",
    "                    \"NC_001854.1\":\"lp28-4\",\n",
    "                    \"NC_000948.1\":\"cp32-1\",\n",
    "                    \"NC_000949.1\":\"cp32-3\",\n",
    "                    \"NC_000950.1\":\"cp32-4\",\n",
    "                    \"NC_000951.1\":\"cp32-6\",\n",
    "                    \"NC_000952.1\":\"cp32-7\",\n",
    "                    \"NC_000953.1\":\"cp32-8\",\n",
    "                    \"NC_000954.1\":\"cp32-9\",\n",
    "                    \"NC_001855.1\":\"lp36\",\n",
    "                    \"NC_001856.1\":\"lp38\",\n",
    "                    \"NC_001857.2\":\"lp54\",\n",
    "                    \"NC_000956.1\":\"lp56\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                     PROCESS HITS                    #\n",
    "#######################################################\n",
    "\n",
    "#Fields=\"query acc.ver, subject acc.ver, % identity, alignment length, mismatches, gap opens, q. start, q. end, s. start, s. end, evalue, bit score\"\n",
    "results = pandas.read_csv(blast_results, sep = '\\t', header=None) # read in blast results .tsv\n",
    "\n",
    "#create ID to Group translation table\n",
    "#{{TODO}}: ID2GROUP.tsv is created by sed on the pan-genome reference fasta. I need to rewrite my sed script in python to plug into this workflow.\n",
    "\n",
    "id2group = pandas.read_csv(seqID_to_group, sep = '\\t', header=None)\n",
    "id2group = pandas.DataFrame({\"ID\":id2group[0],\"group\":id2group[1]})\n",
    "\n",
    "#create a dataframe containing group, geneID, %identity, alignment length, and E-score\n",
    "hits = pandas.DataFrame({\"ID\":results[0],\n",
    "                         \"gene\":results[1],\n",
    "                         \"percent_ident\":results[2],\n",
    "                         \"alignment_length\": results[3],\n",
    "                         \"E-score\": results[10]})\n",
    "\n",
    "hits = hits.drop_duplicates() # I have no idea why blast output duplicates for each hit.... drop them\n",
    "ids = list(hits['ID'].unique()) # pull out unique ID numbers to filter the list by.\n",
    "hits = hits.loc[(hits[\"ID\"].isin(ids)) & (hits[\"gene\"].str.startswith(\"gene-BB\"))] # filter list by IDs then pull out all BB-RS genes\n",
    "\n",
    "#The below two transforms re-order the table into alphabetical order so it makes visual checks much more tricky. prob need to write something to check this. the numbers in -> out match.\n",
    "grouped = hits.groupby('ID') # group rows by ID\n",
    "first_hits = grouped.first() # pull the first row from each ID's group\n",
    "translated_hits = first_hits.merge(id2group,how='left', on = 'ID') #merge em together\n",
    "\n",
    "# this was to check for the presence of a specific gene that was being omitted from the final results. It was present but not being parsed\n",
    "# for whatever reason. This can be removed.\n",
    "#translated_hits[translated_hits.isin(['gene-BB_RS05835'])].stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2b59f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         number of genes:  1486\n",
      "   number of pseudogenes:  68\n",
      " number of annotated CDS:  1515\n",
      "total number of features:  1554\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "#      Get GFF summary for genes and pseudogenes      #\n",
    "#######################################################\n",
    "\n",
    "examiner = GFFExaminer()\n",
    "in_handle = open(bb31_gff)\n",
    "gff_stats = examiner.available_limits(in_handle) # get high level overview of all features in GFF\n",
    "in_handle.close()\n",
    "\n",
    "num_gene = gff_stats['gff_type']['gene',] # set number of genes to summary value from above\n",
    "num_pseudo = gff_stats['gff_type']['pseudogene',] # set number of pseudogenes to summary value from above\n",
    "num_cds= gff_stats['gff_type']['CDS',]\n",
    "num_features = num_gene + num_pseudo # get total number of features. this is to confirm correct parsing later on.\n",
    "print(\"         number of genes: \", num_gene)\n",
    "print(\"   number of pseudogenes: \", num_pseudo)\n",
    "print(\" number of annotated CDS: \", num_cds)\n",
    "print(\"total number of features: \", num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "477df0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                      PARSE GFF                      #\n",
    "#######################################################\n",
    "\n",
    "# parse B31 genome\n",
    "records = SeqIO.to_dict(SeqIO.parse(bb31_fna, \"fasta\"))\n",
    "prot_records = SeqIO.to_dict(SeqIO.parse(bb31_fna, \"fasta\"))\n",
    "\n",
    "limit_info = dict(gff_type=[\"CDS\"])\n",
    "\n",
    "# parse B31 GFF for gene_id parsing, this could probably be done with the protein stuff but BCBio's GFF parser does not parse both for whatever reason. I can either parse genes OR CDS but attempting to do both only gets me genes and I dont feel like re-writing my dict comprehension at this time.\n",
    "in_handle = open(bb31_gff) #set up input handle\n",
    "for rec in GFF.parse(in_handle):\n",
    "    records[rec.id].features = rec.features\n",
    "\n",
    "# parse B31 GFF for protein stuff\n",
    "in_handle = open(bb31_gff) #set up input handle\n",
    "for rec in GFF.parse(in_handle, limit_info=limit_info):\n",
    "    prot_records[rec.id].features = rec.features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d868323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#              Peptide/Protein Analysis               #\n",
    "#######################################################\n",
    "\n",
    "i = 0 # init counting variable\n",
    "protein_info = {} # init dict for protein info.\n",
    "plasmid_ID = \"\" # init plasmid ID\n",
    "\n",
    "for plasmid in prot_records.keys(): # start dict comprehension, go through each plasmid\n",
    "    current_plasmid = prot_records[plasmid] # set current_plasmid as the current iteration through the records dictionary, each key is an individual plasmid\n",
    "    plasmid_ID = plasmid_name_table[current_plasmid.id] # translate NCBI accession ID to the common identifier\n",
    "\n",
    "    for gene in current_plasmid.features: # within each plasmid, look at the SeqFeatures and then iterate through each one.\n",
    "        if gene.id.startswith(\"NC_\"): # if gene.id starts with NC_, it is a larger structure and not a gene, ignore it. the previous method of filtering is not optimal at all and leaves out genes randomly for whatever reason. This method is functional.\n",
    "            pass # skip this feature and iterate loop\n",
    "\n",
    "        else: # if it does not start with the chromosome ID, then pull out the below values\n",
    "            if gene.type == 'CDS':\n",
    "                #print(gene.type) # sanity check and debugging\n",
    "                current_feature = gene # set current_feature to the current iteration of dict comprehension. THIS IS REQUIRED\n",
    "                locus_tag = current_feature.qualifiers['locus_tag'] # extract the current gene locus ID (this is the same as the gene-BB_RS ID used elsewhere and output by blast.)\n",
    "                locus_tag = \"gene-\"+str(locus_tag).strip('\\[\\]\\'') # gotta add the gene- to make it play ball\n",
    "\n",
    "                protein_info[locus_tag] = {} # add current gene to keys in dict, init nested dict.\n",
    "                AA_length = 0 # init length counter\n",
    "                AA_incomplete = False # init boolean for sequence completeness\n",
    "                N_count = 0 # init N counter\n",
    "                AA_ambiguous = False # init boolean for codon ambiguity\n",
    "                Ambig_count = 0 # init ambiguous counter\n",
    "                raw_seq = str(gene.extract(current_plasmid.seq)) # this works, attempted to use a MutableSeq earlier but I'm not working within the biopython class aside from the initial parsing so it isn't needed/definitely will break.\n",
    "\n",
    "                while len(raw_seq) % 3 != 0: # check for multiple of 3 via modulo, if remainder is not 0 then loop over the following\n",
    "                    AA_incomplete = True # set boolean to true\n",
    "                    raw_seq = raw_seq+\"N\" # append an N to the end\n",
    "                    #print(gene.id,\"added an N\") # sanity check\n",
    "                    N_count += 1 # iterate N counter.\n",
    "\n",
    "                AA_seq_raw = translate(raw_seq, table=11, to_stop=True) # translate raw_seq to peptide seq based on translation table 11.\n",
    "\n",
    "                if re.search(\"[XJBZ]\", AA_seq_raw) is not None: # check for ambiguous AAs\n",
    "                    AA_ambiguous = True # set boolean to true\n",
    "                    Ambig_count = len(re.findall(\"[XJBZ]\", AA_seq_raw))\n",
    "\n",
    "                #####\n",
    "                AA_Seq = AA_seq_raw.replace(\"*\",\"\").replace(\"X\",\"\").replace(\"J\",\"L\").replace(\"B\",\"N\").replace(\"Z\",\"Q\") # this is probably wrong, change ambiguous AAs to the non-acid form and flat out remove the fully ambiguous AAs (X) so the calculations will work.\n",
    "                # perhaps I should be generating all possible peptides based on ambiguity and then feeding each into the below calculations. Need to think about/get advice on.\n",
    "                #####\n",
    "                AA_length = len(AA_Seq)\n",
    "                peptide = ProteinAnalysis(str(AA_Seq)) # set up biopython protein analysis object to use the below called methods.\n",
    "\n",
    "                # !! I continually get a div by zero error when it should not be giving me that. I am manually counting AAs and running the percent function to see where it is going wrong.\n",
    "                # !! update it was dragging in ncRNA and that did not play nicely for whatever reason. fixed.\n",
    "                # !! OK so the div/0 error arises when non CDS peptide translations are fed into the counting method. It really despises ncRNA and refuses to count AAs for whatever reason. It was fixed with upstream filtering.\n",
    "\n",
    "                #print(AA_incomplete, AA_ambiguous) # Am I breaking this peptide sequence early on? is the ambiguity breaking it? is the substitution breaking it? give me info.\n",
    "                #AA_content = peptide.count_amino_acids() # count em\n",
    "                #print(AA_content) # display the count\n",
    "                #AA_percent = peptide.get_amino_acids_percent() # this is where the div/0 error arises because the above count fails to count.\n",
    "                #print(AA_percent) # if this works, the rest will too.\n",
    "\n",
    "                # lets get some values for wetlab now.\n",
    "                AA_mol_weight        = peptide.molecular_weight() # get molecular weight\n",
    "                AA_aromaticity       = peptide.aromaticity() # calculate aromaticity based on AA composition\n",
    "                AA_isoelectric       = peptide.isoelectric_point() # calculate isoelectric point\n",
    "                AA_instability_index = peptide.instability_index() # calculate instability index\n",
    "                AA_gravy             = peptide.gravy() # calculate overall hydropathy. {{TODO}} perhaps this would be better represented by individual hydropathy plots for each protein.\n",
    "                AA_sec_struct        = peptide.secondary_structure_fraction() # estimatate percent composition of secondary structures.\n",
    "                AA_helix             = AA_sec_struct[0] # extract percent_helix\n",
    "                AA_turn              = AA_sec_struct[1] # extract percent_turn\n",
    "                AA_sheet             = AA_sec_struct[2] # extract percent_beta_sheet\n",
    "\n",
    "                protein_info[locus_tag] = {'plasmid': plasmid_ID,\n",
    "                                             'gene' : locus_tag,\n",
    "                                        'protein_id': gene.id,\n",
    "                                  'bool_incomplete' : AA_incomplete,\n",
    "                                         'added_Ns' : N_count,\n",
    "                            'bool_ambiguous_codons' : AA_ambiguous,\n",
    "                                  'ambiguous_count' : Ambig_count,\n",
    "                                        'AA_length' : AA_length,\n",
    "                                 'molecular_weight' : AA_mol_weight,\n",
    "                                      'aromaticity' : AA_aromaticity,\n",
    "                                'isoelectric_point' : AA_isoelectric,\n",
    "                                'instability_index' : AA_instability_index,\n",
    "                                            'GRAVY' : AA_gravy,\n",
    "                                       'perc_helix' : AA_helix,\n",
    "                                        'perc_turn' : AA_turn,\n",
    "                                       'perc_sheet' : AA_sheet,\n",
    "                                         'gene_seq' : raw_seq,\n",
    "                                      'peptide_seq' : AA_Seq } # save to dict\n",
    "\n",
    "                # The below would be nice in a log file maybe. This data needs its own table for all genes in BB31\n",
    "                ###################################################################################\n",
    "                #print(\"      Gene Locus ID: \", locus_tag)\n",
    "                #print(\"         protein ID: \", gene.id)\n",
    "                #print(\"                Seq: \", AA_Seq) # translate current CDS to AA via table 11.\n",
    "                #print(\"Incomplete peptide?: \", AA_incomplete)\n",
    "                #print(\" Number of Ns added: \", N_count)\n",
    "                #print(\"     Ambiguous AAs?: \", AA_ambiguous)\n",
    "                #print(\" Ambiguous AA Count: \", Ambig_count)\n",
    "                #print(\"     number of AA's: \",len(AA_Seq))\n",
    "                #print(\"   molecular weight: \",\"%0.2f\" % AA_mol_weight)\n",
    "                #print(\"        aromaticity: \",\"%0.2f\" % AA_aromaticity)\n",
    "                #print(\"  isoelectric point: \",\"%0.2f\" % AA_isoelectric)\n",
    "                #print(\"  instability index: \",\"%0.2f\" % AA_instability_index)\n",
    "                #print(\"              GRAVY: \",\"%0.2f\" % AA_gravy)\n",
    "                #print(\"           helix \\%: \",\"%0.2f\" % AA_helix)\n",
    "                #print(\"            turn \\%: \",\"%0.2f\" % AA_turn)\n",
    "                #print(\"           sheet \\%: \",\"%0.2f\" % AA_sheet)\n",
    "                #print(i) # print current iteration\n",
    "                i += 1 # iterate counter\n",
    "                ###################################################################################\n",
    "\n",
    "            else: # if not CDS, skip this feature.\n",
    "                #print(\"not CDS, skipping\")\n",
    "                pass\n",
    "\n",
    "protein_info = pandas.DataFrame.from_dict(protein_info, orient='index') # turn the dict into a pandas.DataFrame\n",
    "#pprint.pprint(protein_info) # sanity check, look at the table output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37239c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1554\n",
      "features in parsed table is equal to total number of features in GFF. It appears to have parsed successfully.\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "#                 Translate ID to Gene                #\n",
    "#######################################################\n",
    "\n",
    "# {{TODO}}\n",
    "# I need to write some generalized functions to pull this info from GFF files since this is a simple dictionary comprehension\n",
    "# function that I have used previously, although with a few subtle changes.\n",
    "# a generalized function would be very helpful to basically set the desired outputs and a dict to store them in.\n",
    "# or something like that. idk, I'll deal with that after this becomes functional.\n",
    "# actually this might be built into BCBio.GFF somewhere. Need to look into that.\n",
    "\n",
    "ID_to_locus_tag = {} # set up empty dict for IDs and Tags\n",
    "for plasmid in records.keys(): # start dict comprehension, go through each plasmid\n",
    "    current_plasmid = records[plasmid] # set current_plasmid as the current iteration through the records dictionary, each key is an individual plasmid\n",
    "    for gene in current_plasmid.features: # within each plasmid, look at the SeqFeatures and then iterate through each one.\n",
    "        current_feature = gene # set current_feature to the current iteration of dict comprehension. THIS IS REQUIRED\n",
    "        #print(\"current_plasmid: \", current_plasmid.name) # sanity check\n",
    "        #print(\"current feature: \") # sanity check\n",
    "        #print(current_feature) # sanity check\n",
    "        if current_feature.id.startswith(\"NC_\"): # the previous method of filtering is not optimal at all and leaves out genes randomly for whatever reason. This method is functional. {{TODO}}: NEEDS WORK\n",
    "            pass # skip this feature and iterate loop\n",
    "        else: # if it does not start with the chromosome ID, then pull out the below values\n",
    "            ID = str(current_feature.id) # this is the ID value that is also present in the blast hits table.\n",
    "            ID = str(ID.strip('\\[\\]\\'')) # make it format nicely so downstream stuff works correctly\n",
    "            #locus_tag = str(current_feature.qualifiers.get('locus_tag')) # this is the above ID value but without gene- at the beginning. This is redundant and not really necessary atm\n",
    "            #locus_tag = locus_tag.strip('\\[\\]\\'') # see above\n",
    "            old_locus_tag = str(current_feature.qualifiers.get('old_locus_tag', 'NA')) # not all features have an old locus tag, if not present, fill with NA\n",
    "            old_locus_tag = old_locus_tag.strip('\\[\\]\\'') # see double above\n",
    "            ID_to_locus_tag[ID] = old_locus_tag\n",
    "\n",
    "print(len(ID_to_locus_tag)) # check length and compare with # of genes present in GFF\n",
    "if len(ID_to_locus_tag) == num_features:\n",
    "    print(\"features in parsed table is equal to total number of features in GFF. It appears to have parsed successfully.\")\n",
    "else:\n",
    "    print(\"number of features in parsed table is not equal to the number of features present in the GFF. Something went wrong!\")\n",
    "\n",
    "\n",
    "# the below is for visual confirmation of successful parsing. There is no doubt a way to do this more efficiently\n",
    "#i = 1\n",
    "#for key in ID_to_locus_tag:\n",
    "#    print(key, ID_to_locus_tag[key])\n",
    "#    print(i)\n",
    "#    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f57fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                  ANNOTATION PARSING                 #\n",
    "#######################################################\n",
    "\n",
    "# lets try to get product info using gffutils\n",
    "# gff parsing using gffutils is below since BCBio.GFF only extracts parent features......\n",
    "\n",
    "db = gffutils.create_db(bb31_gff, dbfn = 'bb31.db', force=True, gtf_subfeature='CDS', merge_strategy=\"create_unique\")\n",
    "db = gffutils.FeatureDB('bb31.db')\n",
    "#\n",
    "gene_annotations = {} # init dict for annotations\n",
    "for key in ID_to_locus_tag: # iterate through each ID\n",
    "    for f in db.children(key): # for each gene present in the GFF database created above,\n",
    "        gene = str(f['Parent']).strip('\\[\\]\\'') # extract out the gene ID and strip the surrounding mess.\n",
    "        product = f['product'] # extract gene product\n",
    "\n",
    "        if 'Ontology_term' in f.attributes: # check to see if GO term is present\n",
    "            ont_term = str(f['Ontology_term']) # extract term as string\n",
    "        else: # if no term set NA\n",
    "            ont_term = 'NA'\n",
    "\n",
    "        if 'go_function' in f.attributes: # check for GO function\n",
    "            go_fxn = str(f['go_function']) # extract function as str\n",
    "        else: # otherwise NA\n",
    "            go_fxn = 'NA'\n",
    "\n",
    "        if 'go_process' in f.attributes: # check for GO process\n",
    "            go_proc = str(f['go_process']) # extract process as str\n",
    "        else: # otherwise NA\n",
    "            go_proc = 'NA'\n",
    "\n",
    "        gene_annotations[key] = {'gene' : gene,'Product':product, 'GO_term':ont_term, 'GO_process':go_proc, 'GO_function' : go_fxn} # populate annotation dict\n",
    "\n",
    "gene_annotations = pandas.DataFrame.from_dict(gene_annotations, orient='index') # convert to pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3cb002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                   MERGE DATAFRAMES                  #\n",
    "#######################################################\n",
    "\n",
    "# create column in hits df and populate with results of dictionary lookup for each gene present\n",
    "translated_hits['locus_tag'] = translated_hits['gene'].map(ID_to_locus_tag) # map genes to old locus tags\n",
    "# merge annotations table with translated hits table.\n",
    "translated_hits = translated_hits.merge(gene_annotations, how='left', on='gene') # merge annotations\n",
    "translated_hits = translated_hits.merge(protein_info, how='left', on='gene') # merge peptide info\n",
    "translated_hits['gene'] = translated_hits['gene'].str.removeprefix(\"gene-\") # strip this annoying prefix\n",
    "translated_hits['protein_id'] = translated_hits['protein_id'].str.removeprefix(\"cds-\") # and this one too\n",
    "\n",
    "## Also add locus tag to the protein info table\n",
    "protein_table = protein_info # no touch original table\n",
    "protein_table['locus_tag'] = protein_info['gene'].map(ID_to_locus_tag) # map gene ID to locus tag\n",
    "protein_table = protein_table.merge(gene_annotations, how='left', on='gene') # merge with gene annotations\n",
    "protein_table['gene'] = protein_table['gene'].str.removeprefix(\"gene-\") # strip annoying prefix\n",
    "protein_table['protein_id'] = protein_table['protein_id'].str.removeprefix(\"cds-\") # strip annoying prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                   REORDER COLUMNS                   #\n",
    "#######################################################\n",
    "\n",
    "#print(*enumerate(translated_hits.columns))\n",
    "\n",
    "# INITIAL ORDERING\n",
    "# (0, 'ID') (1, 'gene') (2, 'percent_ident') (3, 'alignment_length') (4, 'E-score') (5, 'group') (6, 'locus_tag') (7, 'Product')\n",
    "# (8, 'GO_term') (9, 'GO_process') (10, 'GO_function') (11, 'plasmid') (12, 'protein_id') (13, 'bool_incomplete') (14, 'added_Ns')\n",
    "# (15, 'bool_ambiguous_codons') (16, 'ambiguous_count') (17, 'AA_length') (18, 'molecular_weight') (19, 'aromaticity') (20, 'isoelectric_point')\n",
    "# (21, 'instability_index') (22, 'GRAVY') (23, 'perc_helix') (24, 'perc_turn') (25, 'perc_sheet') (26, 'gene_seq') (27, 'peptide_seq')\n",
    "\n",
    "updated_table = translated_hits.iloc[:,[0,5,11,1,6,2,3,4,7,8,9,10,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27]] # reorder columns\n",
    "#print(updated_table) # sanity check\n",
    "table_no_blast = translated_hits.iloc[:,[0,5,1,6,11,7,8,9,10,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27]] # remove blast stuff\n",
    "\n",
    "#print(*enumerate(updated_table.columns))\n",
    "\n",
    "# and work with the whole genome protein table\n",
    "#print(*enumerate(protein_table.columns))\n",
    "all_proteins = protein_table.iloc[:,[0,1,18,2,19,7,8,3,4,5,6,9,10,11,12,13,14,15,20,21,22,16,17]]\n",
    "#print(*enumerate(all_genes_table.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9a664ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                  WRITE OUTPUT TABLE                 #\n",
    "#######################################################\n",
    "all_proteins.to_csv(all_genes_table, sep='\\t', header=True, index=False) # output all of the above generated peptide information to its own tsv file :)\n",
    "updated_table.to_csv(gwas_output_table, sep='\\t', header=True, index=None) # write table with blast data for GWAS team\n",
    "table_no_blast.to_csv(wetlab_output_table, sep='\\t', header= True, index=None) # write table without blast data for wetlab team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3126e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pangenome_reference ="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
